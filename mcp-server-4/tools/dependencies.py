"""–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è GitHub."""

from typing import Dict, Any, List, Optional

import httpx
from fastmcp import Context
from mcp.types import TextContent
from opentelemetry import trace
from pydantic import Field
import json

from mcp_instance import mcp
from .utils import (
    ToolResult,
    _require_env_vars,
    create_github_client,
    handle_github_error,
    retry_github_request
)
import time

tracer = trace.get_tracer(__name__)


@mcp.tool(
    name="analyze_dependencies",
    description="""üì¶ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è GitHub.

–≠—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞:
- Python: requirements.txt, pyproject.toml, setup.py
- JavaScript/TypeScript: package.json
- Java: pom.xml, build.gradle
- Go: go.mod
- Rust: Cargo.toml

–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –ø—Ä–æ–µ–∫—Ç–∞ –∏ –≤—ã—è–≤–ª–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫.
"""
)
async def analyze_dependencies(
    owner: str = Field(
        ...,
        description="–í–ª–∞–¥–µ–ª–µ—Ü —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è (username –∏–ª–∏ organization name)",
        examples=["octocat", "microsoft", "facebook"]
    ),
    repo: str = Field(
        ...,
        description="–ù–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è",
        examples=["Hello-World", "vscode", "react"]
    ),
    ctx: Context = None
) -> ToolResult:
    """
    üì¶ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è GitHub.
    
    Args:
        owner: –í–ª–∞–¥–µ–ª–µ—Ü —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
        repo: –ù–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
        ctx: –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        
    Returns:
        ToolResult: –†–µ–∑—É–ª—å—Ç–∞—Ç —Å –∞–Ω–∞–ª–∏–∑–æ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        
    Raises:
        McpError: –ü—Ä–∏ –æ—à–∏–±–∫–∞—Ö –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    """
    with tracer.start_as_current_span("analyze_dependencies") as span:
        span.set_attribute("owner", owner)
        span.set_attribute("repo", repo)
        
        await ctx.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è")
        await ctx.report_progress(progress=0, total=100)
        
        try:
            _require_env_vars(["GITHUB_TOKEN"])
            await ctx.report_progress(progress=10, total=100)
            
            client = create_github_client()
            await ctx.info(f"üîß –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è {owner}/{repo}")
            await ctx.report_progress(progress=20, total=100)
            
            await ctx.info("üì° –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å—ã –∫ GitHub API")
            await ctx.report_progress(progress=30, total=100)
            
            # –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –¥–ª—è –ø–æ–∏—Å–∫–∞
            dependency_files = [
                "requirements.txt",
                "pyproject.toml",
                "setup.py",
                "package.json",
                "pom.xml",
                "build.gradle",
                "go.mod",
                "Cargo.toml",
                "composer.json",
                "Gemfile"
            ]
            
            found_files = []
            dependencies_data = {}
            
            # –ò—â–µ–º —Ñ–∞–π–ª—ã –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
            for dep_file in dependency_files:
                try:
                    file_url = f"/repos/{owner}/{repo}/contents/{dep_file}"
                    response = await retry_github_request(
                        client, "GET", file_url, ctx=ctx
                    )
                    file_data = response.json()
                    
                    if file_data.get("type") == "file":
                        found_files.append(dep_file)
                        
                        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
                        content = file_data.get("content", "")
                        encoding = file_data.get("encoding", "base64")
                        
                        if encoding == "base64":
                            import base64
                            try:
                                decoded_content = base64.b64decode(content).decode("utf-8")
                                dependencies_data[dep_file] = decoded_content
                            except:
                                pass
                        
                except httpx.HTTPStatusError as e:
                    if e.response.status_code != 404:
                        raise
                    continue
                except:
                    continue
                
                await ctx.report_progress(progress=30 + (len(found_files) * 5), total=100)
            
            await ctx.report_progress(progress=70, total=100)
            await ctx.info("üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
            analysis_result = {}
            
            for file_name, content in dependencies_data.items():
                deps = []
                
                if file_name == "requirements.txt":
                    # –ü–∞—Ä—Å–∏–º requirements.txt
                    for line in content.split("\n"):
                        line = line.strip()
                        if line and not line.startswith("#"):
                            dep = line.split("==")[0].split(">=")[0].split("<=")[0].split("~=")[0].strip()
                            if dep:
                                deps.append(dep)
                
                elif file_name == "package.json":
                    # –ü–∞—Ä—Å–∏–º package.json
                    try:
                        pkg_data = json.loads(content)
                        deps = list(pkg_data.get("dependencies", {}).keys())
                        deps.extend(list(pkg_data.get("devDependencies", {}).keys()))
                    except:
                        pass
                
                elif file_name == "pyproject.toml":
                    # –ü–∞—Ä—Å–∏–º pyproject.toml (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
                    for line in content.split("\n"):
                        if "=" in line and ("==" in line or ">=" in line or "~=" in line):
                            dep = line.split("=")[0].strip()
                            if dep and not dep.startswith("["):
                                deps.append(dep)
                
                if deps:
                    analysis_result[file_name] = {
                        "file": file_name,
                        "dependencies_count": len(deps),
                        "dependencies": deps[:50]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 50
                    }
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result_text = f"üì¶ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –¥–ª—è {owner}/{repo}\n\n"
            
            if found_files:
                result_text += f"üìÑ –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π:\n"
                for file_name in found_files:
                    result_text += f"  - {file_name}\n"
                result_text += "\n"
                
                if analysis_result:
                    result_text += f"üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π:\n"
                    for file_name, data in analysis_result.items():
                        result_text += f"\n  üìÑ {file_name}:\n"
                        result_text += f"    - –í—Å–µ–≥–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π: {data['dependencies_count']}\n"
                        result_text += f"    - –ü—Ä–∏–º–µ—Ä—ã (—Ç–æ–ø 10):\n"
                        for dep in data["dependencies"][:10]:
                            result_text += f"      ‚Ä¢ {dep}\n"
                else:
                    result_text += "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤.\n"
            else:
                result_text += "‚ùå –§–∞–π–ª—ã –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –∫–æ—Ä–Ω–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è.\n"
                result_text += "   –ü—Ä–æ–≤–µ—Ä—è–ª–∏—Å—å —Ñ–∞–π–ª—ã: requirements.txt, package.json, pyproject.toml –∏ –¥—Ä.\n"
            
            await ctx.report_progress(progress=95, total=100)
            await ctx.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π —É—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω")
            await ctx.report_progress(progress=100, total=100)
            
            span.set_attribute("found_files_count", len(found_files))
            span.set_attribute("analyzed_files_count", len(analysis_result))
            span.set_attribute("success", True)
            
            return ToolResult(
                content=[TextContent(type="text", text=result_text)],
                structured_content={
                    "found_files": found_files,
                    "analysis": analysis_result,
                    "total_dependencies": sum(
                        data["dependencies_count"] 
                        for data in analysis_result.values()
                    )
                },
                meta={"owner": owner, "repo": repo, "operation": "analyze_dependencies"}
            )
            
        except Exception as e:
            span.set_attribute("error", str(e))
            await handle_github_error(e, ctx, f"–∞–Ω–∞–ª–∏–∑–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π {owner}/{repo}")

